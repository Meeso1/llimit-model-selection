# Data Loading and Processing

## Overview
The project uses the `lmarena-human-preference-140k` dataset from HuggingFace. The raw data is loaded via the `datasets` library into a Pandas DataFrame and then converted into strongly-typed data models.

## Data Structure

### `EvaluationEntry`
This is the core unit of data, representing a single comparison between two models (`model_a` and `model_b`) on a specific prompt.

**Fields:**
- `model_a`, `model_b`: Names of the models being compared.
- `winner`: The outcome of the comparison (`model_a`, `model_b`, `tie`, `both_bad`).
- `conversation_history`: A list of `EvaluationMessage` objects representing the shared context (previous turns) leading up to the current prompt. Each message has a `role` (`user` or `assistant`) and `content` (text).
- `user_prompt`: The specific user prompt that elicited the responses being compared.
- `model_a_response`, `model_b_response`: The actual text responses generated by the models.
- `evaluation_session_id`, `evaluation_order`: Metadata tracking the session and turn number.
- `timestamp`: Time of the evaluation.

## Processing Logic (`src/data_loading.py`)

### Data Format
The dataset stores conversations as numpy arrays of message dictionaries. Each message has:
- `role`: Either `"user"` or `"assistant"`
- `content`: A numpy array of content items (dicts with `type="text"` and `text` field)

### Parsing Steps
1. **Text Extraction**: Content arrays are flattened into plain text strings by extracting all items with `type="text"`.
2. **Conversation Parsing**: Each conversation is split into:
   - History: All messages except the last two (alternating user/assistant exchanges)
   - User prompt: Second-to-last message (always role=`"user"`)
   - Model response: Last message (always role=`"assistant"`)
3. **Validation**: Strict checks ensure data integrity:
   - Verifies message roles match expected patterns
   - Validates winner values
   - Checks for required fields
4. **Error Handling**: Rows with invalid data are skipped with warnings that include row identifiers for troubleshooting.

## Usage
To load data:
```python
from src.data_loading import load_training_data
import datasets

dataset = datasets.load_dataset("lmarena-ai/arena-human-preference-140k")
df = dataset["train"].to_pandas()
training_data = load_training_data(df)
```
