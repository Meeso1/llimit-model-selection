# Data Loading and Processing

## Overview
The project supports multiple datasets from HuggingFace:
- `lmarena-ai/arena-human-preference-140k` (lmarena)
- `lmsys/chatbot_arena_conversations` (chatbot_arena)

The raw data is loaded via the `datasets` library into a Pandas DataFrame and then converted into strongly-typed data models. Both datasets are processed into the same internal representation (`TrainingData`).

## Data Structure

### `EvaluationEntry`
This is the core unit of data, representing a single comparison between two models (`model_a` and `model_b`) on a specific prompt.

**Fields:**
- `model_a`, `model_b`: Names of the models being compared.
- `winner`: The outcome of the comparison (`model_a`, `model_b`, `tie`, `both_bad`).
- `conversation_history`: A list of `EvaluationMessage` objects representing the shared context (previous turns) leading up to the current prompt. Each message has a `role` (`user` or `assistant`) and `content` (text).
- `user_prompt`: The specific user prompt that elicited the responses being compared.
- `model_a_response`, `model_b_response`: The actual text responses generated by the models.
- `evaluation_session_id`, `evaluation_order`: Metadata tracking the session and turn number.
- `timestamp`: Time of the evaluation.

## Processing Logic (`src/data_loading.py`)

### Data Format
Both datasets store conversations as numpy arrays of message dictionaries. Each message has:
- `role`: Either `"user"` or `"assistant"`
- `content`: 
  - In `lmarena_human_preference` dataset: A numpy array of content items (dicts with `type="text"` and `text` field)
  - In `chatbot_arena` dataset: A string directly

The data loading functions (`load_training_data_lmarena` and `load_training_data_chatbot_arena`) handle these format differences automatically.

### Parsing Steps
1. **Text Extraction**: Content arrays are flattened into plain text strings by extracting all items with `type="text"`.
2. **Conversation Parsing**: Each conversation is split into:
   - History: All messages except the last two (alternating user/assistant exchanges)
   - User prompt: Second-to-last message (always role=`"user"`)
   - Model response: Last message (always role=`"assistant"`)
3. **Validation**: Strict checks ensure data integrity:
   - Verifies message roles match expected patterns
   - Validates winner values
   - Checks for required fields
4. **Error Handling**: Rows with invalid data are skipped with warnings that include row identifiers for troubleshooting.

## Preprocessing and Caching

After loading, data goes through preprocessing (see `PromptEmbeddingPreprocessor`):
- Filters out ties and "both_bad" outcomes
- Extracts 45 scalar features from each prompt (task type, complexity, domain, style, context, output format)
- Embeds prompts using sentence transformers
- Creates model ID mappings
- **Caches results** based on dataset signature and preprocessor version for reuse

Train/validation splitting happens *after* preprocessing on the preprocessed pairs, ensuring both splits share the same model encoder and feature extraction logic.

**Preprocessor Version**: The preprocessor version (currently "v2") is included in the cache key. When new features are added or preprocessing logic changes, the version should be incremented to invalidate old cached data.

## Usage

### Loading Data Programmatically
To load data from specific datasets:
```python
from src.data_loading import load_training_data_lmarena, load_training_data_chatbot_arena
import datasets

# Load lmarena dataset
lmarena_dataset = datasets.load_dataset("lmarena-ai/arena-human-preference-140k")
lmarena_data = load_training_data_lmarena(lmarena_dataset["train"].to_pandas())

# Load chatbot_arena dataset
chatbot_dataset = datasets.load_dataset("lmsys/chatbot_arena_conversations")
chatbot_data = load_training_data_chatbot_arena(chatbot_dataset["train"].to_pandas())
```

### CLI Configuration
When using the training CLI, specify the dataset in the `data` section of your training specification JSON:

```json
{
  "data": {
    "dataset": "lmarena_human_preference",  // or "chatbot_arena" or "both"
    "max_samples": 10000,
    "validation_split": 0.2,
    "seed": 42
  },
  ...
}
```

Available dataset options:
- `"lmarena_human_preference"` (default): Uses only the lmarena-ai/arena-human-preference-140k dataset
- `"chatbot_arena"`: Uses only the lmsys/chatbot_arena_conversations dataset
- `"both"`: Combines both datasets into a single training set
