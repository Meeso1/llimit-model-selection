{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c436636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from src import data_loading\n",
    "\n",
    "dataset = datasets.load_dataset(\"lmarena-ai/arena-human-preference-140k\")\n",
    "data = data_loading.load_training_data(dataset[\"train\"].to_pandas())\n",
    "print(f\"Successfully loaded {len(data.entries)} entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144d76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.dn_embedding_model import DnEmbeddingModel\n",
    "from src.models.optimizers.adamw_spec import AdamWSpec\n",
    "from src.utils.data_split import ValidationSplit\n",
    "\n",
    "\n",
    "model = DnEmbeddingModel(\n",
    "    hidden_dims=[512, 512, 256, 256, 128, 128, 64, 64],\n",
    "    optimizer_spec=AdamWSpec(\n",
    "        learning_rate=5e-5,\n",
    "        lr_decay_gamma=0.998,\n",
    "    ),\n",
    "    balance_model_samples=True,\n",
    "    \n",
    "    embedding_model_epochs=50,\n",
    "    embedding_model_name=\"all-mpnet-base-v2\",\n",
    "    embedding_model_hidden_dims=[512, 512, 256, 256, 128, 128, 64, 64],\n",
    "    embedding_model_optimizer_spec=AdamWSpec(\n",
    "        learning_rate=5e-5,\n",
    "        lr_decay_gamma=0.998,\n",
    "    ),\n",
    "    triplet_margin=0.2,\n",
    "    regularization_weight=1e-5,\n",
    "    min_model_comparisons=20,\n",
    "    identity_positive_ratio=0.9,\n",
    "    seed=42,\n",
    "    print_every=1,\n",
    ")\n",
    "\n",
    "model.train(data, validation_split=ValidationSplit(val_fraction=0.2, seed=42), epochs=120, batch_size=512)\n",
    "model.save(\"first-try-embedding-model-with-all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63780a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.last_timer.inspect(1)\n",
    "print()\n",
    "model.embedding_model.last_timer.inspect(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344af73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.plotting_utils import plot_loss, plot_accuracy\n",
    "\n",
    "history = model.embedding_model._epoch_logs\n",
    "_, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
    "\n",
    "plot_loss(axes[0, 0], [e.train_loss for e in history], \"Training loss\")\n",
    "plot_loss(axes[0, 1], [e.val_loss for e in history], \"Validation loss\")\n",
    "plot_accuracy(axes[1, 0], [e.train_triplet_accuracy for e in history], \"Training accuracy\")\n",
    "plot_accuracy(axes[1, 1], [e.val_triplet_accuracy for e in history], \"Validation accuracy\")\n",
    "plot_loss(axes[2, 0], [e.train_reg_loss for e in history], \"Training regularization loss\")\n",
    "axes[2, 1].plot([e.duration for e in history])\n",
    "axes[2, 1].set_xlabel(\"Epoch\")\n",
    "axes[2, 1].set_ylabel(\"Duration (s)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff823cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from src.plotting_utils import plot_loss, plot_accuracy\n",
    "\n",
    "history = model.get_history()\n",
    "_, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "plot_loss(axes[0, 0], history.total_loss, \"Training loss\")\n",
    "plot_loss(axes[0, 1], history.val_loss, \"Validation loss\")\n",
    "plot_accuracy(axes[1, 0], history.train_accuracy, \"Training accuracy\")\n",
    "plot_accuracy(axes[1, 1], history.val_accuracy, \"Validation accuracy\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5466a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_models.data_models import InputData\n",
    "from src.preprocessing.prompt_embedding_preprocessor import PromptEmbeddingPreprocessor\n",
    "from src.utils import data_split\n",
    "\n",
    "_, validation_prompts = data_split.train_val_split(PromptEmbeddingPreprocessor.filter_out(data), val_fraction=0.2, seed=42)\n",
    "results = model.predict(InputData(\n",
    "        prompts=validation_prompts,\n",
    "        model_names=model._model_encoder.names,\n",
    "    ),\n",
    "    batch_size=512,\n",
    ").scores\n",
    "\n",
    "sorted_results = sorted(\n",
    "    [(name, float(np.mean(scores)), float(np.std(scores))) for name, scores in results.items()],\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "for name, mean_score, std_score in sorted_results:\n",
    "    print(f\"{(name+\":\"):<{max(len(name) for name, _, _ in sorted_results)+1}s} {mean_score:.6f} Â± {std_score:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
